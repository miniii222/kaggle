{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/minhtriet/a-beginner-guide-for-sale-data-prediction"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom datetime import datetime, date\nfrom dateutil.relativedelta import relativedelta\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom math import ceil\n\nfrom keras.callbacks import LambdaCallback\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, LSTM\nfrom keras.optimizers import RMSprop","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/sales_train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nitems = pd.read_csv('../input/items.csv')\nitem_cats = pd.read_csv('../input/item_categories.csv')\nshops = pd.read_csv('../input/shops.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_shops = test.shop_id.unique()\ntrain = train[train.shop_id.isin(test_shops)]\ntest_items = test.item_id.unique()\ntrain = train[train.item_id.isin(test_items)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_BLOCK_NUM = train.date_block_num.max() #33\nMAX_ITEM = len(test_items)\nMAX_CAT = len(item_cats)\nMAX_YEAR = 3\nMAX_MONTH = 4\nMAX_SHOP = len(test_shops)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Exploration\nshop & item categories 두 관점에서 보겠다"},{"metadata":{},"cell_type":"markdown","source":"## shop_id"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = pd.DataFrame(train.groupby(['shop_id', 'date_block_num'])['item_cnt_day'].sum().reset_index()) #shop_id 별로 월별 판매량\ngrouped.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 5, ncols = 2, sharex=True, sharey = True, figsize = (16,20)) #축 공유\nnum_graph = 10\nid_per_graph = ceil(grouped.shop_id.max() / num_graph) #6\ncount = 0\n\nfor i in range(5) :\n    for j in range(2) :\n        sns.pointplot(x = 'date_block_num', y = 'item_cnt_day', hue = 'shop_id', data = grouped[np.logical_and(count * id_per_graph <= grouped['shop_id'],\n                                                                                                               grouped['shop_id'] < (count + 1)*id_per_graph)], ax = axes[i][j])\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터의 시작이 2013년 1월부터 시작이다. 확실히 연말에 피크 생긴다. 그러므로, 월과 연도를 추가하여 패턴을 파악하도록 하는 것이 좋겠다. 각가의 아템 판매양이 어떻게 되는지 보는 것이 좋겠다. item category도 함께!"},{"metadata":{},"cell_type":"markdown","source":"## item categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.set_index('item_id').join(items.set_index('item_id')).drop('item_name', axis = 1).reset_index()\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['month'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%m'))\ntrain['year'] = train.date.apply(lambda x: datetime.strptime(x, '%d.%m.%Y').strftime('%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 5, ncols = 2, sharex = True, sharey = True, figsize = (16,20))\nnum_graph = 10\nid_per_graph = ceil(train.item_category_id.max() / num_graph)\ncount = 0\n\nfor i in range(5) :\n    for j in range(2) :\n        sns.pointplot(x = 'month', y = 'item_cnt_day', hue = 'item_category_id',\n                     data = train[np.logical_and(count * id_per_graph <= train.item_category_id, train['item_category_id'] < (count + 1) * id_per_graph)], ax = axes[i][j])\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 5, ncols = 2, sharex = True, sharey = True, figsize = (16,20))\nnum_graph = 10\nid_per_graph = ceil(train.item_category_id.max() / num_graph)\ncount = 0\n\nfor i in range(5) :\n    for j in range(2) :\n        sns.pointplot(x = 'date_block_num', y = 'item_cnt_day', hue = 'item_category_id',\n                     data = train[np.logical_and(count * id_per_graph <= train.item_category_id, train['item_category_id'] < (count + 1) * id_per_graph)], ax = axes[i][j])\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['date', 'item_category_id'], axis = 1)\ntrain = train.groupby(['shop_id', 'item_id', 'date_block_num', 'month', 'year']).sum()\ntrain = train.sort_index()\ntrain.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ncnt_scaler = StandardScaler()\n\nscaler.fit(train.item_price.as_matrix().reshape(-1,1))\ncnt_scaler.fit(train.item_cnt_day.as_matrix().reshape(-1,1))\n\ntrain.item_price = scaler.transform(train.item_price.as_matrix().reshape(-1,1))\ntrain.item_cnt_day = scaler.transform(train.item_cnt_day.as_matrix().reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모든 데이터를 training하는 것이 자연스럽지만, 두가지 결점이 있다\n- 2013년 1월 데이터(date_block_num = 0) 가 예측해야 할 데이(2015 11월) 영향이 미미\n- 메모리 에러 ㅜㅜ\n\n**2013,2014 7,8,9,10,11 데이터를 활용**"},{"metadata":{},"cell_type":"markdown","source":"# Missing Data\n- 모든 아이템들이 위 기간에 팔리지는 않았기 때문에 빈 값은 item_cnt_day = 0으로 채운다.\n- item의 가격은 shop과 산 시점에 따라 다르다. 가격은 가장 가까운 과거의 데이터로 채운다."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.reset_index().groupby(['item_id', 'date_block_num', 'shop_id']).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price = train.reset_index().set_index(['item_id', 'shop_id', 'date_block_num'])\nprice = price.sort_index()\nprice.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert(date_block) :\n    date = datetime(2013,1,1) #처음 달\n    date += relativedelta(months = date_block)\n    \n    return (date.month, date.year)\n\n#date_block값을 입력하였을 때, 몇년 몇월인지 알려줌\nprint(convert(6))\nprint(convert(18))\nprint(convert(30))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"price.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def closest_date_block(current_day, item_id, shop_id) :\n    if (item_id, shop_id) in price.index : #item_id와 shop_id가 동일한 경우를 찾을 수 있음\n        search_lst = np.array(price.loc[(item_id, shop_id)].index)\n        \n        return search_lst[np.abs(current_day - search_lst).argmin()]\n    \n    return -1 #item_id와 shop_id가 동일한 경우를 찾을 수 없음\n\ndef closest_price(current_day, item_id, shop_id) :\n    closest_date = closest_date_block(current_day, item_id, shop_id)\n    \n    if closest_date != -1 :\n        return price.loc[(item_id, shop_id, closest_date)]['item_price']\n    \n    return np.nan\n\ndef closest_price_lambda(x) :\n    return closest_date_price(34, x.item_id, x.shop_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert closest_date_block(18,30,5) == 18","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# make training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%who","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del items, item_cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxlen = 4 # 4달\nstep = 1\n# 0: train, 1: val, 2:test\n\nsentences = [[],[],[]]\nnext_chars = [[], []]\nBLOCKS = [6, 18, 30]\n\nfor s in test_shops:\n    shop_items = list(train.loc[s].index.get_level_values(0).unique())\n    for it in shop_items:        \n        for i_index, i in enumerate(BLOCKS):\n            sentence = []\n            closest_pc = closest_price(i, it, s)            \n            for j in range(maxlen+1):\n                if j < maxlen:\n                    if (s, it, i+j) in train.index:\n                        r = train.loc[(s, it, i + j)].to_dict(orient='list')                    \n                        closest_pc = r['item_price'][0]\n                        item_cnt_day = r['item_cnt_day'][0]\n                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': item_cnt_day, \n                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n                    else:\n                        month, year = convert(i+j)                    \n                        row = {'shop_id': s, 'date_block_num': i+j, 'item_cnt_day': 0, \n                               'month': month, 'item_id': it, 'item_price': closest_pc, 'year': year}\n                    sentence.append(row)\n                elif i_index < 2:   # not in test set\n                    next_chars[i_index].append(row)\n            sentences[i_index].append(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train length : ', len(sentences[0]))\nprint('val length : ', len(sentences[1]))\nprint('test length : ', len(sentences[2]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_o = np.array(sentences[0])\nx_val_o = np.array(sentences[1])\nx_test_o = np.array(sentences[2])\ny_train = np.array([x['item_cnt_day'] for x in next_chars[0]])\ny_val = np.array([x['item_cnt_day'] for x in next_chars[1]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length = MAX_SHOP + MAX_ITEM + MAX_MONTH + 1+ 1+ 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%who","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, test, sentences, sentence, next_chars","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## categorical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nshop_dm = dict(zip(test_shops, le.fit_transform(test_shops)))\nitem_dm = dict(zip(test_items, le.fit_transform(test_items)))\nmonth_dm = dict(zip(range(7,11), le.fit_transform(range(7,11))))\n\ndel test_shops, test_items","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vectorize(inp) :\n    print('Vectorization ...')\n    \n    x = np.zeros((len(inp), maxlen, length), dtype = np.float32)\n    \n    for i, sentence in enumerate(inp) :\n        for t, char in enumerate(sentence) :\n            x[i][t][ shop_dm[char['shop_id']] ] = 1        \n            x[i][t][ MAX_SHOP + item_dm[char['item_id']] ] = 1\n            x[i][t][ MAX_SHOP + MAX_ITEM + month_dm[char['month']] ] = 1\n            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 ] = char['item_price']\n            x[i][t][ MAX_SHOP + MAX_ITEM + MAX_MONTH + 1 + 1] = char['item_cnt_day']    \n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = vectorize(x_train_o)\nx_val = vectorize(x_val_o)\nx_test = vectorize(x_test_o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del x_train_o, x_val_o, x_test_o\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('X_train shape : ', x_train.shape)\nprint('X_val shape : ', x_val.shape)\nprint('X_test shape : ', x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Build Model...')\nmodel = Sequential()\nmodel.add(LSTM(32, input_shape = (maxlen, length)))\nmodel.add(Dense(1, activation = 'relu'))\n\noptimizer = RMSprop(lr = 0.005)\nmodel.compile(loss = 'mean_squared_error', optimizer = optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train, y_train, batch_size= 256, epochs = 13,\n                    validation_data = (x_val, y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history.history\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history2 = model.fit(x_val, y_val, batch_size=128, epochs=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_dict = history2.history\nloss = history_dict['loss']\nval_loss = history_dict['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'bo', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and Validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}